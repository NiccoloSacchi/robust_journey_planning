{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pandas import Series\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from math import sin, cos, sqrt, atan2, radians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.90.38.21:4046\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.0.2.6.4.0-91</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>final-proj</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f1f9c82cf28>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName('final-proj')\n",
    "         .master('yarn')\n",
    "         .config('spark.port.maxRetries', 100)\n",
    "         .config('spark.executor.memory', '1g')\n",
    "         .config('spark.executor.instances', '2')\n",
    "         .config('spark.executor.cores', '2')\n",
    "         .config('spark.jars.packages', 'org.apache.spark:spark-streaming-kafka-0-8_2.11:2.2.0')\n",
    "         .getOrCreate())\n",
    "\n",
    "sc = spark.sparkContext\n",
    "conf = sc.getConf()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata file contains all the stations and gps coordinates\n",
    "metadata = spark.read.text('/datasets/project/metadata/BFKOORD_GEO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.446770</td>\n",
       "      <td>26.074412</td>\n",
       "      <td>Bucuresti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.901549</td>\n",
       "      <td>1.811446</td>\n",
       "      <td>Calais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.284212</td>\n",
       "      <td>1.075329</td>\n",
       "      <td>Canterbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.729172</td>\n",
       "      <td>-3.543547</td>\n",
       "      <td>Exeter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46.922368</td>\n",
       "      <td>9.733756</td>\n",
       "      <td>Fideris, Bahnhof</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude   latitude              stop\n",
       "0  44.446770  26.074412         Bucuresti\n",
       "1  50.901549   1.811446            Calais\n",
       "2  51.284212   1.075329        Canterbury\n",
       "3  50.729172  -3.543547            Exeter\n",
       "4  46.922368   9.733756  Fideris, Bahnhof"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting and adding new columns to the spark dataframe\n",
    "split_col = pyspark.sql.functions.split(metadata['value'], \" % \")\n",
    "split_left = pyspark.sql.functions.split(split_col.getItem(0), \" +\")\n",
    "metadata = metadata.withColumn('longitude', split_left.getItem(2))\n",
    "metadata = metadata.withColumn('latitude', split_left.getItem(1))\n",
    "metadata = metadata.withColumn('stop', split_col.getItem(1))\n",
    "metadata = metadata.drop('value')\n",
    "\n",
    "metadataPandas = metadata.toPandas()\n",
    "metadataPandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>47.378177</td>\n",
       "      <td>8.540192</td>\n",
       "      <td>Z端rich HB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      longitude  latitude       stop\n",
       "2379  47.378177  8.540192  Z端rich HB"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Z端rich HB is the starting point\n",
    "zurich_coord = metadataPandas[metadataPandas['stop'] == 'Z端rich HB']\n",
    "zurich_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the distance of gps coordinates\n",
    "def compute_distance(lat1, lon1, lat2, lon2):\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0 \n",
    "    \n",
    "    lat1 = radians(lat1)\n",
    "    lon1 = radians(lon1)\n",
    "    lat2 = radians(lat2)\n",
    "    lon2 = radians(lon2)\n",
    "    \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "    return distance*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only stations inside 10km\n",
    "mask = metadataPandas.apply(lambda x: compute_distance(\n",
    "    float(zurich_coord['latitude']), \n",
    "    float(zurich_coord['longitude']),\n",
    "    float(x['latitude']), \n",
    "    float(x['longitude'])) <= 10000, axis=1)\n",
    "metadataPandas = metadataPandas[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with the source data\n",
    "df = spark.read.option(\"delimiter\", \";\").option(\"header\", \"true\").csv('/datasets/project/istdaten/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the needed information\n",
    "df = df.select(\n",
    "          df['BETRIEBSTAG'].alias('date'), \n",
    "          df['FAHRT_BEZEICHNER'].alias('id'), \n",
    "          df['PRODUKT_ID'].alias('transport_type'), \n",
    "          df['LINIEN_ID'].alias('train_number'), \n",
    "          df['HALTESTELLEN_NAME'].alias('stop_name'), \n",
    "          df['ANKUNFTSZEIT'].alias('arrival_time'), \n",
    "          df['AN_PROGNOSE'].alias('actual_arrival_time'),\n",
    "          df['AN_PROGNOSE_STATUS'].alias('status_arrival_time'),\n",
    "          df['ABFAHRTSZEIT'].alias('departure_time'),\n",
    "          df['AB_PROGNOSE'].alias('actual_departure_time'),\n",
    "          df['AB_PROGNOSE_STATUS'].alias('status_departure_time'),\n",
    "          df['DURCHFAHRT_TF'].alias('stop_here'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the departure and arrival delays\n",
    "formatTS1 = \"dd.MM.yyyy HH:mm:ss\"\n",
    "formatTS2 = \"dd.MM.yyyy HH:mm\"\n",
    "\n",
    "departure_delay = (F.unix_timestamp('actual_departure_time', formatTS1) - \n",
    "        F.unix_timestamp('departure_time', formatTS2))\n",
    "arrival_delay = (F.unix_timestamp('actual_arrival_time', formatTS1) - \n",
    "        F.unix_timestamp('arrival_time', formatTS2))\n",
    "\n",
    "# extract the day of the week\n",
    "def get_week_day(date):\n",
    "    converted_date = datetime.datetime.strptime(str(date), \"%d.%m.%Y\")\n",
    "    return converted_date.weekday()\n",
    "\n",
    "week_day_udf = F.udf(get_week_day, IntegerType())\n",
    "\n",
    "# udf to fill NaN departure (arrival) values with the arrival (departure) time\n",
    "@udf('string')\n",
    "def fillWithOther(a, b):\n",
    "    if (a is None):\n",
    "        return b\n",
    "    return a\n",
    "    \n",
    "# date parser\n",
    "date = F.to_date('date', 'dd.MM.yyyy')\n",
    "\n",
    "# First filtering. arrival_delay and departure_delay columns\n",
    "df_filtered = (df.filter((df.status_arrival_time == 'GESCHAETZT') | (df.status_departure_time == 'GESCHAETZT'))\n",
    "     .withColumn(\"arrival_delay\", arrival_delay)\n",
    "     .withColumn(\"departure_delay\", departure_delay)\n",
    "                      )\n",
    "\n",
    "# Handling the NaN values\n",
    "df_with_delays = df_filtered.select('id', 'train_number', 'stop_name', 'arrival_time', 'arrival_delay', 'departure_time', 'departure_delay')\n",
    "df_with_delays = df_with_delays.fillna(0, ['departure_delay', 'arrival_delay'])\n",
    "df_with_delays = (df_with_delays\n",
    "                  .withColumn('arrival_time2', fillWithOther(df_with_delays.arrival_time, df_with_delays.departure_time))\n",
    "                  .withColumn('departure_time2', fillWithOther(df_with_delays.departure_time, df_with_delays.arrival_time))\n",
    "                  .drop(df_with_delays.departure_time).drop(df_with_delays.arrival_time)\n",
    "                 )\n",
    "df_with_delays = df_with_delays.withColumnRenamed('departure_time2', 'departure_time').withColumnRenamed('arrival_time2', 'arrival_time')\n",
    "# Adding the day of the week\n",
    "df_with_delays = df_with_delays.withColumn(\"day_week\", week_day_udf(F.split(df_with_delays.arrival_time, \" \")[0]))\n",
    "\n",
    "# Filtering outliers\n",
    "df_with_delays = df_with_delays.filter((df_with_delays['arrival_delay'] > -1000) &\n",
    "                                       (df_with_delays['arrival_delay'] < 1000) &\n",
    "                                       (df_with_delays['departure_delay'] > -1000) &\n",
    "                                       (df_with_delays['departure_delay'] < 1000)\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the stops that are not in the metadata\n",
    "# Adding a new column 'info' containing all the needed information\n",
    "# Grouping by trip id\n",
    "# Collect the list of the 'info' rows in the group\n",
    "df_grouped = (df_with_delays\n",
    "    .filter(df_with_delays.stop_name.isin(metadataPandas.stop.tolist()))\n",
    "    .withColumn('info', F.struct('stop_name', F.split('arrival_time', \" \")[1], 'arrival_delay', F.split('departure_time', \" \")[1], 'departure_delay', 'day_week'))\n",
    "    .groupby('id')\n",
    "    .agg(F.collect_list('info').alias('info'))\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting the groups\n",
    "groups = df_grouped.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>dep_node</th>\n",
       "      <th>arr_node</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>mean_delay</th>\n",
       "      <th>std_delay</th>\n",
       "      <th>dep_day</th>\n",
       "      <th>arr_day</th>\n",
       "      <th>delta</th>\n",
       "      <th>delays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85:11:18388:001</td>\n",
       "      <td>Dietlikon</td>\n",
       "      <td>Stettbach</td>\n",
       "      <td>23:14</td>\n",
       "      <td>23:17</td>\n",
       "      <td>60.151515</td>\n",
       "      <td>105.014023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(-2, 341, 194, 346, -71, 70, -5, 41, 3, 1, -20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85:11:18388:001</td>\n",
       "      <td>Stettbach</td>\n",
       "      <td>Z端rich Stadelhofen</td>\n",
       "      <td>23:18</td>\n",
       "      <td>23:22</td>\n",
       "      <td>67.666667</td>\n",
       "      <td>97.935459</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>(1, 316, 187, 406, -1, 37, -1, 18, 12, 9, 13, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85:11:18388:001</td>\n",
       "      <td>Z端rich Stadelhofen</td>\n",
       "      <td>Z端rich HB</td>\n",
       "      <td>23:23</td>\n",
       "      <td>23:26</td>\n",
       "      <td>14.606061</td>\n",
       "      <td>92.191695</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>(-45, 221, 125, 354, -46, -25, -40, -39, -38, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85:11:18388:001</td>\n",
       "      <td>Z端rich HB</td>\n",
       "      <td>Z端rich Hardbr端cke</td>\n",
       "      <td>23:29</td>\n",
       "      <td>23:31</td>\n",
       "      <td>40.606061</td>\n",
       "      <td>38.486150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(38, 97, 47, 234, 19, 43, 29, 25, 40, 37, 23, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85:11:18388:001</td>\n",
       "      <td>Z端rich Hardbr端cke</td>\n",
       "      <td>Z端rich Altstetten</td>\n",
       "      <td>23:31</td>\n",
       "      <td>23:35</td>\n",
       "      <td>3.545455</td>\n",
       "      <td>40.070322</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>(-22, 27, 18, 174, -34, 1, -22, -22, -7, 7, -1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           trip_id            dep_node            arr_node dep_time arr_time  \\\n",
       "0  85:11:18388:001           Dietlikon           Stettbach    23:14    23:17   \n",
       "1  85:11:18388:001           Stettbach  Z端rich Stadelhofen    23:18    23:22   \n",
       "2  85:11:18388:001  Z端rich Stadelhofen           Z端rich HB    23:23    23:26   \n",
       "3  85:11:18388:001           Z端rich HB   Z端rich Hardbr端cke    23:29    23:31   \n",
       "4  85:11:18388:001   Z端rich Hardbr端cke   Z端rich Altstetten    23:31    23:35   \n",
       "\n",
       "   mean_delay   std_delay dep_day arr_day  delta  \\\n",
       "0   60.151515  105.014023       0       0    3.0   \n",
       "1   67.666667   97.935459       0       0    4.0   \n",
       "2   14.606061   92.191695       0       0    3.0   \n",
       "3   40.606061   38.486150       0       0    2.0   \n",
       "4    3.545455   40.070322       0       0    4.0   \n",
       "\n",
       "                                              delays  \n",
       "0  (-2, 341, 194, 346, -71, 70, -5, 41, 3, 1, -20...  \n",
       "1  (1, 316, 187, 406, -1, 37, -1, 18, 12, 9, 13, ...  \n",
       "2  (-45, 221, 125, 354, -46, -25, -40, -39, -38, ...  \n",
       "3  (38, 97, 47, 234, 19, 43, 29, 25, 40, 37, 23, ...  \n",
       "4  (-22, 27, 18, 174, -34, 1, -22, -22, -7, 7, -1...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to compute the delta between departur and arrival time. If the delta is too high, it will be filtered\n",
    "def compute_delta(arrival, departure, day):\n",
    "    d1 = datetime.datetime.strptime(arrival, \"%H:%M\")\n",
    "    d2 = datetime.datetime.strptime(departure, \"%H:%M\")\n",
    "    d1_ts = time.mktime(d1.timetuple())\n",
    "    d2_ts = time.mktime(d2.timetuple())\n",
    "    res = int(d2_ts-d1_ts) / 60\n",
    "    if (day > 0):\n",
    "        res = res + 60 * 24 * day\n",
    "    return res\n",
    "\n",
    "def delays(s):\n",
    "    return tuple(s)\n",
    "    if s.shape[0] < 2:\n",
    "        return s\n",
    "    return list(s)\n",
    "\n",
    "# DataFrame containing the final schedule\n",
    "schedule = pd.DataFrame(columns= ['trip_id', 'dep_node', 'arr_node', \n",
    "                                  'dep_time', 'arr_time',\n",
    "                                  'mean_delay', 'std_delay', \n",
    "                                  'dep_day', 'arr_day', 'delta', 'delays'])\n",
    "\n",
    "# Iterating through groups\n",
    "for group in groups:\n",
    "    trip_id = group[0]\n",
    "    info = group[1]\n",
    "    p = pd.DataFrame(info, columns=['stop', 'arrival_time', 'arrival_delay','departure_time', 'departure_delay', 'week_day'])\n",
    "    \n",
    "    # Computing the mean of arrival and departure delays\n",
    "    c = p.groupby(['week_day', 'arrival_time', 'departure_time', 'stop']).agg([np.mean, np.std, delays])\n",
    "\n",
    "    c = c.reset_index()\n",
    "    c.columns = [' '.join(col).strip() for col in c.columns.values]\n",
    "    \n",
    "    # Creating all the couples of (start_station, arrival_station) for each trip. The order of the schedule \n",
    "    # is manteined by the groupby operation. We can have the same schedule for different days of the week, \n",
    "    # or the schedule can even change on different days. The compute_delta function calculates the time interval\n",
    "    # between each couple: if the interval is too high, it means that a new trip started and the couple has to be\n",
    "    # discarded. We also consider trips that are scheduled between midnight (in this case the week_day changes). \n",
    "    partialResult = pd.DataFrame([(trip_id,\n",
    "                        c.loc[i, 'stop'], \n",
    "                        c.loc[i+1, 'stop'], \n",
    "                        c.loc[i, 'departure_time'], \n",
    "                        c.loc[i+1, 'arrival_time'], \n",
    "                        c.loc[i+1, 'arrival_delay mean'],\n",
    "                        c.loc[i+1, 'arrival_delay std'], \n",
    "                        c.loc[i, 'week_day'], \n",
    "                        c.loc[i+1, 'week_day'], \n",
    "                        compute_delta(c.loc[i, 'departure_time'], \n",
    "                                      c.loc[i+1, 'arrival_time'], \n",
    "                                      c.loc[i+1, 'week_day']-c.loc[i, 'week_day']),\n",
    "                        c.loc[i+1, 'arrival_delay delays']) \n",
    "                                  for i in range(len(c)-1)],\n",
    "                     columns= ['trip_id', 'dep_node', 'arr_node', \n",
    "                               'dep_time', 'arr_time',\n",
    "                               'mean_delay', 'std_delay', \n",
    "                               'dep_day', 'arr_day', 'delta', 'delays'])\n",
    "    # Need to merge the last station with the first, in case of a trip that starts on sunday night and finisches\n",
    "    # on monday morning\n",
    "    m = len(c)-1\n",
    "    partialResult = partialResult.append([{'trip_id': trip_id,\n",
    "                'dep_node': c.loc[m, 'stop'], \n",
    "                'arr_node': c.loc[0, 'stop'], \n",
    "                'dep_time': c.loc[m, 'departure_time'], \n",
    "                'arr_time': c.loc[0, 'arrival_time'],\n",
    "                'mean_delay': c.loc[m, 'arrival_delay mean'], \n",
    "                'std_delay': c.loc[m, 'arrival_delay std'], \n",
    "                'dep_day': c.loc[m, 'week_day'], \n",
    "                'arr_day': c.loc[0, 'week_day'],\n",
    "                'delta': compute_delta(c.loc[m, 'departure_time'], c.loc[0, 'arrival_time'], c.loc[0, 'week_day']+7-c.loc[m, 'week_day']),\n",
    "                'delays': c.loc[m, 'arrival_delay delays']\n",
    "                 }], ignore_index=True\n",
    "               )\n",
    "    # Filtering the wrong couples and couples where the start and stop stations are the same\n",
    "    partialResult = partialResult[partialResult.delta < 180]\n",
    "    partialResult = partialResult[partialResult.dep_node != partialResult.arr_node]\n",
    "    #partialResult = partialResult.drop(['delta'], axis=1)\n",
    "    schedule = schedule.append(partialResult)\n",
    "\n",
    "schedule.reset_index(drop=True, inplace=True)\n",
    "schedule.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>dep_node</th>\n",
       "      <th>arr_node</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>mean_delay</th>\n",
       "      <th>std_delay</th>\n",
       "      <th>dep_day</th>\n",
       "      <th>arr_day</th>\n",
       "      <th>delta</th>\n",
       "      <th>delays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>85:11:19256:001</td>\n",
       "      <td>Z端rich HB</td>\n",
       "      <td>Z端rich Oerlikon</td>\n",
       "      <td>15:14</td>\n",
       "      <td>15:12</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>(-66,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4008</th>\n",
       "      <td>85:11:19254:001</td>\n",
       "      <td>Z端rich HB</td>\n",
       "      <td>Z端rich Oerlikon</td>\n",
       "      <td>14:44</td>\n",
       "      <td>14:42</td>\n",
       "      <td>-139.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>(-139,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15175</th>\n",
       "      <td>85:11:19253:001</td>\n",
       "      <td>Z端rich HB</td>\n",
       "      <td>Z端rich Oerlikon</td>\n",
       "      <td>14:17</td>\n",
       "      <td>14:16</td>\n",
       "      <td>54.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(54,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15302</th>\n",
       "      <td>85:11:19285:001</td>\n",
       "      <td>Z端rich HB</td>\n",
       "      <td>Z端rich Oerlikon</td>\n",
       "      <td>22:17</td>\n",
       "      <td>22:16</td>\n",
       "      <td>156.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(156,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19164</th>\n",
       "      <td>85:11:19247:001</td>\n",
       "      <td>Z端rich HB</td>\n",
       "      <td>Z端rich Oerlikon</td>\n",
       "      <td>12:47</td>\n",
       "      <td>12:46</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>(94,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               trip_id   dep_node         arr_node dep_time arr_time  \\\n",
       "1307   85:11:19256:001  Z端rich HB  Z端rich Oerlikon    15:14    15:12   \n",
       "4008   85:11:19254:001  Z端rich HB  Z端rich Oerlikon    14:44    14:42   \n",
       "15175  85:11:19253:001  Z端rich HB  Z端rich Oerlikon    14:17    14:16   \n",
       "15302  85:11:19285:001  Z端rich HB  Z端rich Oerlikon    22:17    22:16   \n",
       "19164  85:11:19247:001  Z端rich HB  Z端rich Oerlikon    12:47    12:46   \n",
       "\n",
       "       mean_delay  std_delay dep_day arr_day  delta   delays  \n",
       "1307        -66.0        NaN       0       0   -2.0   (-66,)  \n",
       "4008       -139.0        NaN       0       0   -2.0  (-139,)  \n",
       "15175        54.0        NaN       0       0   -1.0    (54,)  \n",
       "15302       156.0        NaN       3       3   -1.0   (156,)  \n",
       "19164        94.0        NaN       0       0   -1.0    (94,)  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We found some wrong schedules, always between Zurich HB and Zurich Oerlikon. \n",
    "# We suppose that these are errors, because in other days the same schedule doesn't include Zurich Oerlikon\n",
    "schedule[(schedule['dep_time'] > schedule['arr_time']) & (schedule['dep_day'] == schedule['arr_day'])].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the trips that have to be modified\n",
    "trip_id_to_modify = schedule[(schedule['dep_time'] > schedule['arr_time']) & (schedule['dep_day'] == schedule['arr_day'])]['trip_id']\n",
    "\n",
    "# Modifying the wrong rows\n",
    "for i, row in schedule.iterrows():\n",
    "    if ((schedule.loc[i, 'trip_id'] in list(trip_id_to_modify.values)) &\n",
    "       (schedule.loc[i, 'arr_node'] == 'Z端rich Oerlikon')):\n",
    "        schedule.loc[i, 'arr_node'] = schedule.loc[i+1, 'arr_node']\n",
    "        schedule.loc[i, 'arr_time'] = schedule.loc[i+1, 'arr_time']\n",
    "        schedule.loc[i, 'mean_delay'] = schedule.loc[i+1, 'mean_delay']\n",
    "        schedule.loc[i, 'std_delay'] = schedule.loc[i+1, 'std_delay']\n",
    "        \n",
    "# Eliminating the wrong rows\n",
    "schedule = schedule[ (~schedule['trip_id'].isin(list(trip_id_to_modify.values)))\n",
    "        | ((schedule['trip_id'].isin(list(trip_id_to_modify.values)))\n",
    "           & (schedule['dep_node'] != 'Z端rich Oerlikon'  ) )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>dep_node</th>\n",
       "      <th>arr_node</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>mean_delay</th>\n",
       "      <th>std_delay</th>\n",
       "      <th>dep_day</th>\n",
       "      <th>arr_day</th>\n",
       "      <th>delays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85:11:18388:001</td>\n",
       "      <td>Dietlikon</td>\n",
       "      <td>Stettbach</td>\n",
       "      <td>23:14:00</td>\n",
       "      <td>23:17:00</td>\n",
       "      <td>60.151515</td>\n",
       "      <td>105.014023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(-2, 341, 194, 346, -71, 70, -5, 41, 3, 1, -20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85:11:18388:001</td>\n",
       "      <td>Stettbach</td>\n",
       "      <td>Z端rich Stadelhofen</td>\n",
       "      <td>23:18:00</td>\n",
       "      <td>23:22:00</td>\n",
       "      <td>67.666667</td>\n",
       "      <td>97.935459</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 316, 187, 406, -1, 37, -1, 18, 12, 9, 13, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85:11:18388:001</td>\n",
       "      <td>Z端rich Stadelhofen</td>\n",
       "      <td>Z端rich HB</td>\n",
       "      <td>23:23:00</td>\n",
       "      <td>23:26:00</td>\n",
       "      <td>14.606061</td>\n",
       "      <td>92.191695</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(-45, 221, 125, 354, -46, -25, -40, -39, -38, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85:11:18388:001</td>\n",
       "      <td>Z端rich HB</td>\n",
       "      <td>Z端rich Hardbr端cke</td>\n",
       "      <td>23:29:00</td>\n",
       "      <td>23:31:00</td>\n",
       "      <td>40.606061</td>\n",
       "      <td>38.486150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(38, 97, 47, 234, 19, 43, 29, 25, 40, 37, 23, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85:11:18388:001</td>\n",
       "      <td>Z端rich Hardbr端cke</td>\n",
       "      <td>Z端rich Altstetten</td>\n",
       "      <td>23:31:00</td>\n",
       "      <td>23:35:00</td>\n",
       "      <td>3.545455</td>\n",
       "      <td>40.070322</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(-22, 27, 18, 174, -34, 1, -22, -22, -7, 7, -1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           trip_id            dep_node            arr_node dep_time arr_time  \\\n",
       "0  85:11:18388:001           Dietlikon           Stettbach 23:14:00 23:17:00   \n",
       "1  85:11:18388:001           Stettbach  Z端rich Stadelhofen 23:18:00 23:22:00   \n",
       "2  85:11:18388:001  Z端rich Stadelhofen           Z端rich HB 23:23:00 23:26:00   \n",
       "3  85:11:18388:001           Z端rich HB   Z端rich Hardbr端cke 23:29:00 23:31:00   \n",
       "4  85:11:18388:001   Z端rich Hardbr端cke   Z端rich Altstetten 23:31:00 23:35:00   \n",
       "\n",
       "   mean_delay   std_delay dep_day arr_day  \\\n",
       "0   60.151515  105.014023       0       0   \n",
       "1   67.666667   97.935459       0       0   \n",
       "2   14.606061   92.191695       0       0   \n",
       "3   40.606061   38.486150       0       0   \n",
       "4    3.545455   40.070322       0       0   \n",
       "\n",
       "                                              delays  \n",
       "0  (-2, 341, 194, 346, -71, 70, -5, 41, 3, 1, -20...  \n",
       "1  (1, 316, 187, 406, -1, 37, -1, 18, 12, 9, 13, ...  \n",
       "2  (-45, 221, 125, 354, -46, -25, -40, -39, -38, ...  \n",
       "3  (38, 97, 47, 234, 19, 43, 29, 25, 40, 37, 23, ...  \n",
       "4  (-22, 27, 18, 174, -34, 1, -22, -22, -7, 7, -1...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change time type and drop/rename columns\n",
    "schedule = (schedule.drop(['delta'], axis=1))\n",
    "\n",
    "def make_time(entry):\n",
    "    #h, m = entry.split(':')\n",
    "    return pd.Timedelta(entry+':00')\n",
    "\n",
    "schedule['dep_time'] = schedule['dep_time'].apply(lambda x: make_time(x))\n",
    "schedule['arr_time'] = schedule['arr_time'].apply(lambda x: make_time(x))\n",
    "          \n",
    "schedule.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>dep_node</th>\n",
       "      <th>arr_node</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>mean_delay</th>\n",
       "      <th>std_delay</th>\n",
       "      <th>dep_day</th>\n",
       "      <th>arr_day</th>\n",
       "      <th>delta</th>\n",
       "      <th>delays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000</td>\n",
       "      <td>Bonstetten-Wettswil</td>\n",
       "      <td>Bonstetten-Wettswil, Bahnhof</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.121084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000</td>\n",
       "      <td>Waldegg, Birmensdorferstrasse</td>\n",
       "      <td>Waldegg, Post</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>163.432216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000</td>\n",
       "      <td>Waldegg, Birmensdorferstrasse</td>\n",
       "      <td>Uitikon Waldegg, Bahnhof</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>287.582974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000</td>\n",
       "      <td>Z端rich, Goldbrunnenplatz</td>\n",
       "      <td>Z端rich, Zwinglihaus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>262.946946</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000</td>\n",
       "      <td>Z端rich HB</td>\n",
       "      <td>Z端rich HB SZU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140.199392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trip_id                       dep_node                      arr_node  \\\n",
       "0    0000            Bonstetten-Wettswil  Bonstetten-Wettswil, Bahnhof   \n",
       "1    0000  Waldegg, Birmensdorferstrasse                 Waldegg, Post   \n",
       "2    0000  Waldegg, Birmensdorferstrasse      Uitikon Waldegg, Bahnhof   \n",
       "3    0000       Z端rich, Goldbrunnenplatz           Z端rich, Zwinglihaus   \n",
       "4    0000                      Z端rich HB                 Z端rich HB SZU   \n",
       "\n",
       "   dep_time  arr_time  mean_delay  std_delay  dep_day  arr_day  delta  delays  \n",
       "0       NaN       NaN   57.121084        0.0      NaN      NaN    NaN     NaN  \n",
       "1       NaN       NaN  163.432216        0.0      NaN      NaN    NaN     NaN  \n",
       "2       NaN       NaN  287.582974        0.0      NaN      NaN    NaN     NaN  \n",
       "3       NaN       NaN  262.946946        0.0      NaN      NaN    NaN     NaN  \n",
       "4       NaN       NaN  140.199392        0.0      NaN      NaN    NaN     NaN  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the walking times between stations. Keeping only stations within 300m\n",
    "walk = pd.DataFrame(columns= ['trip_id', 'dep_node', 'arr_node', \n",
    "                              'dep_time', 'arr_time',\n",
    "                              'mean_delay', 'std_delay', \n",
    "                              'dep_day', 'arr_day', 'delta', 'delays'])\n",
    "for _, stop1 in metadataPandas.iterrows():\n",
    "    for _, stop2 in metadataPandas.iterrows():\n",
    "        if (stop1.stop != stop2.stop):\n",
    "            distance = compute_distance(float(stop1.latitude), float(stop1.longitude), \n",
    "                                       float(stop2.latitude), float(stop2.longitude))\n",
    "            if (distance <= 300):\n",
    "                walk = walk.append({'trip_id': '0000', \n",
    "                                    'dep_node': stop1.stop, \n",
    "                                    'arr_node': stop2.stop, \n",
    "                                    'mean_delay': distance, # considering 1m/s\n",
    "                                    'std_delay': 0.0}, ignore_index=True)\n",
    "\n",
    "walk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule = schedule.append(walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule.to_pickle(\"data/schedule_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>dep_node</th>\n",
       "      <th>arr_node</th>\n",
       "      <th>dep_day</th>\n",
       "      <th>arr_day</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>delays</th>\n",
       "      <th>num_delays</th>\n",
       "      <th>walking_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85:11:18388:001</td>\n",
       "      <td>Dietlikon</td>\n",
       "      <td>Stettbach</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days 23:14:00</td>\n",
       "      <td>0 days 23:17:00</td>\n",
       "      <td>(-2, 341, 194, 346, -71, 70, -5, 41, 3, 1, -20...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85:11:18388:001</td>\n",
       "      <td>Stettbach</td>\n",
       "      <td>Z端rich Stadelhofen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days 23:18:00</td>\n",
       "      <td>0 days 23:22:00</td>\n",
       "      <td>(1, 316, 187, 406, -1, 37, -1, 18, 12, 9, 13, ...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85:11:18388:001</td>\n",
       "      <td>Z端rich Stadelhofen</td>\n",
       "      <td>Z端rich HB</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days 23:23:00</td>\n",
       "      <td>0 days 23:26:00</td>\n",
       "      <td>(-45, 221, 125, 354, -46, -25, -40, -39, -38, ...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85:11:18388:001</td>\n",
       "      <td>Z端rich HB</td>\n",
       "      <td>Z端rich Hardbr端cke</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days 23:29:00</td>\n",
       "      <td>0 days 23:31:00</td>\n",
       "      <td>(38, 97, 47, 234, 19, 43, 29, 25, 40, 37, 23, ...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85:11:18388:001</td>\n",
       "      <td>Z端rich Hardbr端cke</td>\n",
       "      <td>Z端rich Altstetten</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0 days 23:31:00</td>\n",
       "      <td>0 days 23:35:00</td>\n",
       "      <td>(-22, 27, 18, 174, -34, 1, -22, -22, -7, 7, -1...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           trip_id            dep_node            arr_node dep_day arr_day  \\\n",
       "0  85:11:18388:001           Dietlikon           Stettbach       0       0   \n",
       "1  85:11:18388:001           Stettbach  Z端rich Stadelhofen       0       0   \n",
       "2  85:11:18388:001  Z端rich Stadelhofen           Z端rich HB       0       0   \n",
       "3  85:11:18388:001           Z端rich HB   Z端rich Hardbr端cke       0       0   \n",
       "4  85:11:18388:001   Z端rich Hardbr端cke   Z端rich Altstetten       0       0   \n",
       "\n",
       "          dep_time         arr_time  \\\n",
       "0  0 days 23:14:00  0 days 23:17:00   \n",
       "1  0 days 23:18:00  0 days 23:22:00   \n",
       "2  0 days 23:23:00  0 days 23:26:00   \n",
       "3  0 days 23:29:00  0 days 23:31:00   \n",
       "4  0 days 23:31:00  0 days 23:35:00   \n",
       "\n",
       "                                              delays  num_delays walking_time  \n",
       "0  (-2, 341, 194, 346, -71, 70, -5, 41, 3, 1, -20...        33.0          NaT  \n",
       "1  (1, 316, 187, 406, -1, 37, -1, 18, 12, 9, 13, ...        33.0          NaT  \n",
       "2  (-45, 221, 125, 354, -46, -25, -40, -39, -38, ...        33.0          NaT  \n",
       "3  (38, 97, 47, 234, 19, 43, 29, 25, 40, 37, 23, ...        33.0          NaT  \n",
       "4  (-22, 27, 18, 174, -34, 1, -22, -22, -7, 7, -1...        33.0          NaT  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedule = pd.read_pickle(\"data/schedule_raw.pkl\")\n",
    "\n",
    "schedule.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# put the walking time in the arrival time\n",
    "schedule.loc[schedule.trip_id==\"0000\", \"walking_time\"] = schedule.loc[schedule.trip_id == \"0000\", \"mean_delay\"].apply(lambda secs: pd.Timedelta(\"00:00:\"+str(secs)))\n",
    "\n",
    "# add column with the number of delays per edge\n",
    "schedule.loc[~schedule.delays.isnull(), \"num_delays\"] = schedule.delays.loc[~schedule.delays.isnull()].apply(lambda x: np.NaN if x == np.NaN else len(x))\n",
    "\n",
    "# sort columns and drop mean_delay and std_delay\n",
    "schedule = schedule[[\"trip_id\", \"dep_node\", \"arr_node\", \"dep_day\", \"arr_day\", \"dep_time\", \"arr_time\", \"delays\", \"num_delays\", \"walking_time\"]].copy()\n",
    "\n",
    "schedule.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drop edges with **few delays**.\n",
    "\n",
    "Many edges happened **only few times** (we can see it  from the collected number of delays). To build our schedule we drop all the trips that happened **less times than a treshold** because if a trip took place 10 times over 33 weeks then it is reasonable to not consider it in the schedule. Notice that our schedule has been computed **week-wise** because we want to extract a schedule for each day of the week. Therefore, we won't have a different schedule for special days like Easter or Christmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate bus/metro/train edges from walking edges\n",
    "no_walk = schedule[(schedule.trip_id != \"0000\")]\n",
    "walk = schedule[(schedule.trip_id == \"0000\")]\n",
    "\n",
    "# verify how many null values are in the columns\n",
    "# print(\"Null values in bus/metro/train edges:\\n\", no_walk.isnull().sum())\n",
    "# print(\"\\nNull values in walking edges:\\n\", walk.isnull().sum())\n",
    "\n",
    "# check how many delays per bus/metro/train edge we have \n",
    "print(\"Number of delays per bus/metro/train edge:\\n\", no_walk.num_delays.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and keep into the schedule only trips happened more than treshold times\n",
    "treshold = 20\n",
    "no_walk = no_walk[no_walk.num_delays >= treshold]\n",
    "no_walk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check again the number of delays. The schedule is now half as big and more meaningful\n",
    "no_walk.num_delays.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Clusterize** all the edges depending on their delays. Edges with similar delays will be associated with the same cluster and each cluster will be associated to a **gamma distribution** initialized with the mean and standart deviation of the delays of the whole cluster. \n",
    "\n",
    "We use KMeans to clusterize the edges, however, each edge has between 20 to 33 unordered delays so we extracted the `[20, 30, 40, 50, 60, 70, 80]` qth percentiles for each edge and used them as the features of that edge. This allows to represent more meaningfully the delay distribution of each edge while also dropping some possible outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = [20, 30, 40, 50, 60, 70, 80]\n",
    "X = pd.DataFrame(\n",
    "    columns=percentiles,\n",
    ")\n",
    "for p in percentiles:\n",
    "    X[p] = no_walk.delays.apply(lambda delays: np.percentile(delays, p))\n",
    "    \n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the features we can run the **KMeans**. Note that the index is the same as the initial dataframe, i.e. we obviously know which percentiles belong to which edge, therefore we can proceed in the clustering. We run KMeans for several number of clusters and plot their respective inertia, i.e. the **within-cluster sum-of-squares**. Then we use the elbow method to choose the more reasonable number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n_clusters = [10, 50, 100, 200, 300, 500, 800]\n",
    "# n_clusters = np.arange(10, 100, 20)\n",
    "\n",
    "kmeans = {}\n",
    "for n_cluster in n_clusters:\n",
    "    print(\"Fitting on K=\"+str(n_cluster) + \"...\")\n",
    "    model = KMeans(n_cluster, random_state=0, n_jobs=10)\n",
    "    kmeans[n_cluster] = model\n",
    "    \n",
    "    model.fit(X)\n",
    "\n",
    "plt.grid()\n",
    "plt.ylabel(\"inertia\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.plot(n_clusters, [model.inertia_ for _, model in kmeans.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the best K and get the corresponding labels\n",
    "K = 200\n",
    "X['labels'] = kmeans[K].labels_\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a random subset of the clusters and use only the two percentiles 30 and 70 as dimensions\n",
    "num_clusters_to_plt = 5\n",
    "clusters = np.random.choice(K, num_clusters_to_plt, replace=False)\n",
    "cluster_mapping = dict(zip(clusters, range(num_clusters_to_plt)))\n",
    "\n",
    "small = X[X['labels'].isin(clusters)].copy()\n",
    "small['labels'] = small['labels'].apply(lambda label: cluster_mapping[label]) # map the labels to an integer in [0, 1, ..., num_clusters_to_plt-1] so the color is automatically chosen well\n",
    "\n",
    "plt.grid()\n",
    "plt.scatter(small[30], small[70], c=small['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule = pd.concat([no_walk, walk], axis=0)\n",
    "schedule.loc[X.index, \"label\"] = X[\"labels\"]\n",
    "\n",
    "print(schedule.shape)\n",
    "schedule.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule.to_pickle(\"data/schedule_clustered.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a distribution to each cluster\n",
    "\n",
    "We now create a **distribution** for each cluster and store them in the schedule.\n",
    "Why?\n",
    "\n",
    "- We have few samples per edge which may not be representative enough of its delay distribution.\n",
    "- It is reasonable that some edges' delays are dependent. The clusters have hopefully grouped edges whose delays are jointly dependent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule = pd.read_pickle(\"data/schedule_clustered.pkl\")\n",
    "schedule.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- collect **all the delays** for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the labels of the clusters\n",
    "clusters_labels = sorted(schedule[\"label\"].dropna().astype(int).unique())\n",
    "\n",
    "# collect all the delays for each cluster\n",
    "cluster_delays = {} # map cluster -> list fo delays\n",
    "for c_id in clusters_labels:\n",
    "    cluster = schedule[schedule[\"label\"] == c_id]\n",
    "    cluster_delays[c_id] = np.array([delay for edge_delays in cluster.delays for delay in edge_delays])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **fit a gamma** for each cluster and plot corresponding distributions and histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = {} # map cluster label -> gamma distribution\n",
    "\n",
    "# #clusters (K) = 200 = 5*40\n",
    "ncols = 5\n",
    "nrows = 40\n",
    "fig, axs = plt.subplots(nrows, ncols, figsize=(4*ncols, 4*nrows))\n",
    "\n",
    "axs = np.ndenumerate(axs)\n",
    "\n",
    "# i = 0\n",
    "for cl, delays in cluster_delays.items():\n",
    "#     if i>=10:\n",
    "#         break\n",
    "#     i+=1\n",
    "    \n",
    "    _, ax = next(axs)\n",
    "    \n",
    "    sns.set(color_codes=True)\n",
    "\n",
    "    # plot histogram\n",
    "    ax.set(xlabel='Delay [s]')\n",
    "    sns.distplot(delays, bins=100, kde=False, ax=ax, norm_hist=True)\n",
    "    \n",
    "    # fit the gamma on the delays of the cluster\n",
    "    if cl in [70, 94]:\n",
    "        # these two clusters are best fitted in this way\n",
    "        gammas[cl] = gamma(\n",
    "            *gamma.fit(\n",
    "                delays,\n",
    "                loc=delays.min()\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        gammas[cl] = gamma(\n",
    "            *gamma.fit(\n",
    "                delays,\n",
    "                floc=delays.min()-1e-10)\n",
    "        )\n",
    "\n",
    "    # plot the gamma's pdf on the same plot\n",
    "    x = np.linspace(delays.min(),delays.max(),1000)\n",
    "    ax.plot(x, gammas[cl].pdf(x), label='Gamma distribution')\n",
    "    ax.set_title(\"Cluster:\" + str(cl))\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the **gammas fit reasonibly well** the delays of the clusters! Let's see the probabilities of the delays being **lower than 5 minutes** (300 seconds):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([gamma.cdf(300) for _, gamma in gammas.items()]).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the probabilities are high, it means that there is often a high probability that the transports do less than 5 minutes of delay and we can safely take a connection whose departure is scheduled 5 minutes after our arrival. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- add a new column to the `schedule` to **store**, for each edge, **the distribution** of its cluster. Then, store the obtained `schedule`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c_id in clusters_labels:\n",
    "    schedule.loc[schedule[\"label\"] == c_id, \"distribution\"] = gammas[c_id]\n",
    "schedule.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule.to_pickle(\"data/schedule_clustered.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final clean \n",
    "Add/remove the columns to obtain the final DataFrame that will be used by the `Planner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule = pd.read_pickle(\"data/schedule_clustered.pkl\")\n",
    "\n",
    "# keep only columns used by the algorithm\n",
    "schedule = schedule[[\"trip_id\", \"dep_node\", \"arr_node\", \"dep_day\", \"arr_day\", \"dep_time\", \"arr_time\", \"distribution\", \"walking_time\"]]\n",
    "\n",
    "# the prob column will store the probability of taking the edge, i.e. of taking a mean of transport at a specific time\n",
    "schedule[\"prob\"] = np.NaN\n",
    "# the label column indicates the status of the edge\n",
    "schedule[\"label\"] = Status.Unvisited\n",
    "# the prev_edge column indicates the previous edge taken on a path and will allow to reconstruct the whole path\n",
    "schedule[\"prev_edge\"] = np.NaN\n",
    "\n",
    "schedule.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule.to_pickle(\"data/schedule_clean.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
